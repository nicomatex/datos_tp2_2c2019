{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import feature_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_generation.get_features()\n",
    "features_types = feature_generation.get_features_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_appended_dataset():\n",
    "    \"\"\"Carga ambos dataframes (train y test) y devuelve un solo dataframe que es el resultado de realizar un\n",
    "    append entre ambos. El dataset de test esta al final.\"\"\"\n",
    "\n",
    "    train = pd.read_csv('./data/train.csv', index_col='id', parse_dates=['fecha'])\n",
    "    test = pd.read_csv('./data/test.csv', index_col='id', parse_dates=['fecha'])\n",
    "    df = train.append(test, sort=False)\n",
    "   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_test(df):\n",
    "    \"\"\"Separa df compuesto por sus primeras 240.000 filas de train.csv y sus 60.000 ultimas filas de test\n",
    "    en los dos dataframes correspondientes.\"\"\"\n",
    "    \n",
    "    train = df.head(240000)\n",
    "    test = df.tail(60000).drop('precio', axis=1)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets():\n",
    "    \"\"\"Carga ambos dataframes (train y test) y devuelve dos datasets en el formato:\n",
    "    train_df, test_df\"\"\"\n",
    "\n",
    "    df = load_appended_dataset()\n",
    "    return separate_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_featured_appended_dataset():\n",
    "    \"\"\"Carga el .csv con los features generados, y lo formatea para ahorrar memoria. Devuelve un unico\n",
    "    dataframe cuyas primeras 240.000 filas son de train.csv y sus ultimas 60.000 de test.\"\"\"\n",
    "      \n",
    "    df = load_appended_dataset()\n",
    "    \n",
    "    csv_names = feature_generation.get_csvs_names()\n",
    "    features_types = feature_generation.get_features_types()\n",
    "    \n",
    "    for file in csv_names:\n",
    "        ruta = 'features/'+file+'.csv'\n",
    "        add = pd.read_csv(ruta, index_col='id')\n",
    "        df = pd.merge(df, add, how='left', on='id')\n",
    "           \n",
    "    for categoria in features_types.keys():\n",
    "        for tipo in features_types[categoria]:\n",
    "            castear = features_types[categoria][tipo]\n",
    "            if (tipo == 'bernoulli'):\n",
    "                df[castear] = df[castear].astype('uint8')\n",
    "            elif (tipo == 'float'):\n",
    "                df[castear] = df[castear].astype('float')\n",
    "            elif (tipo == 'uint8'):\n",
    "                df[castear] = df[castear].astype('uint8')\n",
    "            elif (tipo == 'uint16'):\n",
    "                df[castear] = df[castear].astype('uint16')\n",
    "            elif (tipo == 'uint32'):\n",
    "                df[castear] = df[castear].astype('uint32')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_featured_datasets():\n",
    "    \"\"\"Devuelve dos datasets en el formato:\n",
    "    train_df, test_df\n",
    "    Para los datasets con las features generadas.\"\"\"\n",
    "    \n",
    "    df = load_featured_appended_dataset()\n",
    "    return separate_train_test(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre procesamiento de datasets externos\n",
    "### Cotizacion USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "usd = pd.read_csv('external_datasets/usd_mxn_diario.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### funciones aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aniomes(x):\n",
    "    anio=x[6:]\n",
    "    mes=x[3:5]\n",
    "    return anio+mes\n",
    "\n",
    "def numeric(x):\n",
    "    entero, fraccion = x.split(',')\n",
    "    return int(entero) + int(fraccion)/10000\n",
    "\n",
    "def varianza(x):\n",
    "    x = x.rstrip('%')\n",
    "    entero, fraccion = x.split(',')\n",
    "    num = entero+\".\"+fraccion\n",
    "    return float(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "usd['aniomes'] = usd['Fecha'].map(aniomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = ['Último', 'Apertura', 'Máximo', 'Mínimo']\n",
    "for valor in valores:\n",
    "    usd[valor] = usd[valor].map(numeric)\n",
    "    \n",
    "usd['usd_varianza'] = usd['% var.'].map(varianza)\n",
    "usd['daily_mean'] = usd.apply(lambda x: (x['Último'] + x['Apertura'])/2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "usd = usd[['aniomes', 'usd_varianza', 'daily_mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "usd = usd.groupby('aniomes')['usd_varianza', 'daily_mean'].agg({'usd_varianza':'sum', 'daily_mean':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usd_varianza</th>\n",
       "      <th>daily_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aniomes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201201</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>13.419316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201202</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>12.789329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201203</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>12.734559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201204</td>\n",
       "      <td>1.67</td>\n",
       "      <td>13.047955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201205</td>\n",
       "      <td>9.99</td>\n",
       "      <td>13.630126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         usd_varianza  daily_mean\n",
       "aniomes                          \n",
       "201201          -6.71   13.419316\n",
       "201202          -1.50   12.789329\n",
       "201203          -0.27   12.734559\n",
       "201204           1.67   13.047955\n",
       "201205           9.99   13.630126"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "usd.to_csv('data/usd_mxn_featured.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volcanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('external_datasets/volcanes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['properties/OBJECTID', 'properties/LAT', 'properties/LONG_']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['id', 'lat', 'long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19.030365</td>\n",
       "      <td>-97.268213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>18.562021</td>\n",
       "      <td>-95.198504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>19.493241</td>\n",
       "      <td>-102.251431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>18.973674</td>\n",
       "      <td>-101.717852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>19.308206</td>\n",
       "      <td>-110.806474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>-104.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>-113.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>29.338829</td>\n",
       "      <td>-114.517599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>21.849758</td>\n",
       "      <td>-105.885230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>18.303998</td>\n",
       "      <td>-94.730072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lat        long\n",
       "id                       \n",
       "19  19.030365  -97.268213\n",
       "20  18.562021  -95.198504\n",
       "21  19.493241 -102.251431\n",
       "22  18.973674 -101.717852\n",
       "23  19.308206 -110.806474\n",
       "..        ...         ...\n",
       "62  20.830000 -104.820000\n",
       "59  28.500000 -113.750000\n",
       "54  29.338829 -114.517599\n",
       "9   21.849758 -105.885230\n",
       "60  18.303998  -94.730072\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/volcanes_featured.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llenado de valores nulos en tipo de propiedad\n",
    "Funcion que es llamada desde feature_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_tipo(x):\n",
    "    lista = ['casas', 'departamento', 'casa', 'terrenos', 'terreno', 'departamentos',\n",
    "             'apartamento', 'apartamentos', 'comercio', 'locales', 'condominio', 'residencia']\n",
    "    palabras = x.lower().split(' ')\n",
    "    categorias=[]\n",
    "    for palabra in palabras:\n",
    "        if palabra in lista:\n",
    "            categorias.append(palabra)\n",
    "    if len(categorias)==0:\n",
    "        return ['Otros']\n",
    "    elif len(categorias)>1:\n",
    "        return casas_condominio(categorias)\n",
    "    return categorias\n",
    "\n",
    "def casas_condominio(lista):\n",
    "    for palabra in lista:\n",
    "        if palabra == 'condominio':\n",
    "            return ['condominio']\n",
    "    return lista\n",
    "\n",
    "def translate_tiposdepropiedad(x):\n",
    "    translate = {'casas':'Casa', 'departamento':'Apartamento', 'casa':'Casa', 'terrenos':'Terreno',\n",
    "                 'terreno':'Terreno', 'departamentos':'Apartamento', 'apartamento':'Apartamento',\n",
    "                 'apartamentos':'Apartamento', 'comercio':'Comercial', 'locales':'Comercial',\n",
    "                 'condominio':'Casa en condominio', 'residencia':'Casa', 'Otros':'Otros'}\n",
    "    return translate[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_tipodepropiedad_nulls(nulos):\n",
    "    nulos['tipodepropiedad_titulo'] = nulos['titulo'].map(buscar_tipo)\n",
    "    nulos['tipodepropiedad_titulo'] = nulos['tipodepropiedad_titulo'].map(lambda x: translate_tiposdepropiedad(x[0]))\n",
    "    \n",
    "    return nulos.drop('tipodepropiedad', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
